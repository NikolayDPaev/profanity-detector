{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "from distance import levenshteinDistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting initial list of bad words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English bad words translated to bulgarian. <br>\n",
    "And from bulgarian to english. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/english-bad-words.txt\") as file:\n",
    "    english_original = [line.rstrip() for line in file]\n",
    "\n",
    "with open(\"data/english-bad-words-translated.txt\") as file:\n",
    "    english_translated = [line.rstrip() for line in file]\n",
    "\n",
    "with open(\"data/english-bad-words-translated-back.txt\") as file:\n",
    "    english_translated_back = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will filter the words that does not translate back to the original word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(english_original, english_translated, english_translated_back)\n",
    "stable_translations = set([\n",
    "    translation[1] for translation in zipped\n",
    "        if levenshteinDistance(translation[0], translation[2]) < 3\n",
    "        and levenshteinDistance(translation[0], translation[1]) > 3\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stable_translations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mlist\u001b[39m(\u001b[43mstable_translations\u001b[49m), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/bad_words_translated.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[0;32m      3\u001b[0m     outfile\u001b[38;5;241m.\u001b[39mwrite(json_object)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stable_translations' is not defined"
     ]
    }
   ],
   "source": [
    "json_object = json.dumps(list(stable_translations), indent=4, ensure_ascii=False)\n",
    "with codecs.open(\"data/bad_words_translated.json\", \"w\", \"utf-8\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying bad words from BG Jargon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bgjargon.json', 'r', encoding=\"utf-8\") as f:\n",
    "    dictionary = json.load(f)\n",
    "\n",
    "with open('data/bgjargon_words.json', 'r', encoding=\"utf-8\") as f:\n",
    "    words = set(json.load(f))\n",
    "\n",
    "with open('data/bad_words_translated.json', 'r', encoding=\"utf-8\") as f:\n",
    "    translated_words = set(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all words from bg jargon that have tags - some of the translated bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2674"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_bad_tags = {}\n",
    "\n",
    "for key, value in dictionary.items():\n",
    "    if key in translated_words or any(map(lambda x: x in translated_words, value['tags'])):\n",
    "        dictionary_bad_tags[key] = value\n",
    "\n",
    "len(dictionary_bad_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second iteration - all words that have tags which are already marked as bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_bad_tags_deep = dictionary_bad_tags.copy()\n",
    "\n",
    "for key, value in dictionary.items():\n",
    "    if any(map(lambda x: x in dictionary_bad_tags.keys(), value['tags'])):\n",
    "        dictionary_bad_tags_deep[key] = value\n",
    "\n",
    "len(dictionary_bad_tags_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(dictionary_bad_tags_deep, indent=4, ensure_ascii=False)\n",
    "with codecs.open(\"data/bgjargon_bad_tags.json\", \"w\", \"utf-8\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same operation as before but equals is replaced with levenshtein distance < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3460"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_bad_tags_ld = {}\n",
    "\n",
    "for key, value in dictionary.items():\n",
    "    for word in translated_words:\n",
    "        if levenshteinDistance(word, key) < 2 or any(map(lambda x: levenshteinDistance(x, word) < 2, value['tags'])):\n",
    "            dictionary_bad_tags_ld[key] = value\n",
    "            break\n",
    "\n",
    "len(dictionary_bad_tags_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4669"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_bad_tags_deep_ld = dictionary_bad_tags_ld.copy()\n",
    "\n",
    "for key, value in dictionary.items():\n",
    "    if any(map(lambda x: x in dictionary_bad_tags_ld.keys(), value['tags'])):\n",
    "        dictionary_bad_tags_deep_ld[key] = value\n",
    "\n",
    "len(dictionary_bad_tags_deep_ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating single list of bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = list(translated_words)\n",
    "bad_words += [word.lower() for word in dictionary_bad_tags.keys() if len(word.split(' ')) == 1]\n",
    "\n",
    "json_object = json.dumps(list(set(bad_words)), indent=4, ensure_ascii=False)\n",
    "with codecs.open(\"data/bad_words_1.json\", \"w\", \"utf-8\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "\n",
    "bad_words += [word.lower() for word in dictionary_bad_tags_ld.keys() if len(word.split(' ')) == 1]\n",
    "json_object = json.dumps(list(set(bad_words)), indent=4, ensure_ascii=False)\n",
    "with codecs.open(\"data/bad_words_2.json\", \"w\", \"utf-8\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "\n",
    "bad_words += [word.lower() for word in dictionary_bad_tags_deep_ld.keys() if len(word.split(' ')) == 1]\n",
    "json_object = json.dumps(list(set(bad_words)), indent=4, ensure_ascii=False)\n",
    "with codecs.open(\"data/bad_words_3.json\", \"w\", \"utf-8\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
