{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tokenizers import Tokenizer\n",
    "from preprocessing import cyrillize\n",
    "\n",
    "import json\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(f) -> list[str]:\n",
    "    all = []\n",
    "    for a in json.load(f):\n",
    "        sentences = a['content'].lower().split('.')\n",
    "        all.append(a['name'].lower())\n",
    "        all += sentences\n",
    "\n",
    "    return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/unsupervised_comments.json', 'r', encoding=\"utf-8\") as f:\n",
    "    unsupervised_comments = json.load(f)\n",
    "\n",
    "with open('data/blitz_articles.json', 'r', encoding=\"utf-8\") as f:\n",
    "    sentences = get_sentences(f)\n",
    "\n",
    "with open('data/dnes_bg_articles.json', 'r', encoding=\"utf-8\") as f:\n",
    "    sentences += get_sentences(f)\n",
    "\n",
    "with open('data/pik_articles.json', 'r', encoding=\"utf-8\") as f:\n",
    "    sentences += get_sentences(f)\n",
    "\n",
    "\n",
    "unsupervised_corpus = unsupervised_comments + sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the supervised corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/blitz_comments.json', 'r', encoding=\"utf-8\") as f:\n",
    "    supervised_comments = [{'comment': cyrillize(d['comment']), 'label': d['label']} for d in json.load(f) if 'label' in d]\n",
    "\n",
    "supervised_p = len([s for s in supervised_comments if s['label'] == 'p'])\n",
    "supervised_n = len([s for s in supervised_comments if s['label'] == 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bgjargon.json', 'r', encoding=\"utf-8\") as f:\n",
    "    bgjargon = json.load(f)\n",
    "\n",
    "with open('data/bad_words_2.json', 'r', encoding=\"utf-8\") as f:\n",
    "    bad_words = set(json.load(f))\n",
    "\n",
    "for w in bad_words:\n",
    "    if w in bgjargon:\n",
    "        for meaning in bgjargon[w]['meanings']:\n",
    "            if len(meaning['example']) > 0 and supervised_p < supervised_n:\n",
    "                supervised_p += 1\n",
    "                supervised_comments.append({'comment': meaning['example'], 'label': 'p'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"data/tokenizer_comments_bgjargon_articles_end_start.json\")\n",
    "token2ind = tokenizer.get_vocab()\n",
    "ind2token = tokenizer.id_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_corpus = [tokenizer.encode(c.lower()).tokens for c in unsupervised_corpus]\n",
    "supervised_comments = [{'comment': tokenizer.encode(c['comment'].lower()).tokens, 'label': c['label']} for c in supervised_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_comments(supervised_comments, test_fraction = 0.1):\n",
    "    random.seed(42)\n",
    "    random.shuffle(supervised_comments)\n",
    "    test_count = int(len(supervised_comments) * test_fraction)\n",
    "    test_comments = supervised_comments[:test_count]\n",
    "    train_comments = supervised_comments[test_count:]\n",
    "    return test_comments, train_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre training BiLSTM on the unsuppervised corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '[STR]'\n",
    "end_token = '[END]'\n",
    "unk_token = '[UNK]'\n",
    "pad_token = '[PAD]'\n",
    "\n",
    "batchSize = 32\n",
    "emb_size = 50\n",
    "hid_size = 100\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "test_comments, train_comments  = split_comments(supervised_comments, test_fraction = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, token2ind, unk_token, pad_token, end_token):\n",
    "        super(BiLSTMLanguageModelPack, self).__init__()\n",
    "        self.token2ind = token2ind\n",
    "        self.unk_token_idx = token2ind[unk_token]\n",
    "        self.pad_token_idx = token2ind[pad_token]\n",
    "        self.end_token_idx = token2ind[end_token]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "        self.embed = torch.nn.Embedding(len(token2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(2*hidden_size,len(token2ind))\n",
    "\n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        comments = [[self.token2ind.get(w,self.unk_token_idx) for w in s] for s in source]\n",
    "        comments_padded = [ s+(m-len(s))*[self.pad_token_idx] for s in comments]\n",
    "        return torch.t(torch.tensor(comments_padded, dtype=torch.long, device=device))\n",
    "\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.embed(X)\n",
    "\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        m = X.shape[0]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths, enforce_sorted=False))\n",
    "\n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        output = output.view(m, batch_size, 2, self.hidden_size)\n",
    "        # left to right and right to left in shift the prediction to i + 1 and i - 1 for the right to left\n",
    "        # we shift them to make them predict a single position\n",
    "        t = torch.cat((output[:-2,:,0,:], output[2:,:,1,:]),2)\n",
    "        Z = self.projection(t.flatten(0,1))\n",
    "\n",
    "        Y_bar = X[1:-1].flatten(0,1)\n",
    "        Y_bar[Y_bar==self.end_token_idx] = self.pad_token_idx\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.pad_token_idx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0 / 3834 10.310538291931152\n",
      "0 : 800 / 3834 8.16960334777832\n",
      "0 : 1600 / 3834 7.5089850425720215\n",
      "0 : 2400 / 3834 6.998119831085205\n",
      "0 : 3200 / 3834 7.3599162101745605\n",
      "1 : 0 / 3834 6.544349670410156\n",
      "1 : 800 / 3834 6.728677749633789\n",
      "1 : 1600 / 3834 5.192967414855957\n",
      "1 : 2400 / 3834 5.2113165855407715\n",
      "1 : 3200 / 3834 5.614673614501953\n",
      "2 : 0 / 3834 5.205222129821777\n",
      "2 : 800 / 3834 5.428623676300049\n",
      "2 : 1600 / 3834 3.627659559249878\n",
      "2 : 2400 / 3834 3.7056515216827393\n",
      "2 : 3200 / 3834 3.785240411758423\n",
      "3 : 0 / 3834 3.791712522506714\n",
      "3 : 800 / 3834 4.237063884735107\n",
      "3 : 1600 / 3834 2.621879816055298\n",
      "3 : 2400 / 3834 2.8304057121276855\n",
      "3 : 3200 / 3834 2.746354341506958\n",
      "4 : 0 / 3834 2.838104009628296\n",
      "4 : 800 / 3834 3.262881278991699\n",
      "4 : 1600 / 3834 2.0043952465057373\n",
      "4 : 2400 / 3834 2.146798610687256\n",
      "4 : 3200 / 3834 2.059828996658325\n"
     ]
    }
   ],
   "source": [
    "blm = BiLSTMLanguageModelPack(emb_size, hid_size, token2ind, unk_token, pad_token, end_token).to(device)\n",
    "optimizer = torch.optim.Adam(blm.parameters(), lr=0.01)\n",
    "\n",
    "idx = np.arange(len(train_comments), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "for e in range(5):\n",
    "    for b in range(0, len(idx), batchSize):\n",
    "        batch = [unsupervised_corpus[i] for i in idx[b:min(b+batchSize, len(idx))]]\n",
    "        H = blm(batch)\n",
    "        optimizer.zero_grad()\n",
    "        H.backward()\n",
    "        optimizer.step()\n",
    "        if b % 100 == 0:\n",
    "            print(e, ':', b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, test_comments, batchSize):\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(0,len(test_comments),batchSize):\n",
    "        batch = test_comments[b:min(b+batchSize, len(test_comments))]\n",
    "        l = sum(len(s)-1 for s in batch)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * lm(batch)\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3425.637464189045"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(blm, [c['comment'] for c in supervised_comments], batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning on the supervised comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, langModel):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.langModel = langModel\n",
    "        self.classProjection = torch.nn.Linear(2*langModel.hidden_size, 2)\n",
    "\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.langModel.preparePaddedBatch(source)\n",
    "        E = self.langModel.embed(X)\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        _, (h,c) = self.langModel.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths, enforce_sorted=False))\n",
    "        h = h.view(2,batch_size,self.langModel.hidden_size)\n",
    "\n",
    "        Z = self.classProjection(torch.cat([h[0],h[1]],1))\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0 / 3834 0.6981102228164673\n",
      "0 : 160 / 3834 0.9466759562492371\n",
      "0 : 320 / 3834 0.434436172246933\n",
      "0 : 480 / 3834 0.620633602142334\n",
      "0 : 640 / 3834 0.648489236831665\n",
      "0 : 800 / 3834 0.6455889344215393\n",
      "0 : 960 / 3834 0.663154661655426\n",
      "0 : 1120 / 3834 0.737922191619873\n",
      "0 : 1280 / 3834 0.5722798109054565\n",
      "0 : 1440 / 3834 0.6227002143859863\n",
      "0 : 1600 / 3834 0.5432533025741577\n",
      "0 : 1760 / 3834 0.6211169958114624\n",
      "0 : 1920 / 3834 0.6690309047698975\n",
      "0 : 2080 / 3834 0.6981790065765381\n",
      "0 : 2240 / 3834 0.6512628793716431\n",
      "0 : 2400 / 3834 0.6554851531982422\n",
      "0 : 2560 / 3834 0.6771443486213684\n",
      "0 : 2720 / 3834 0.664113461971283\n",
      "0 : 2880 / 3834 0.5335915684700012\n",
      "0 : 3040 / 3834 0.6502116322517395\n",
      "0 : 3200 / 3834 0.7770610451698303\n",
      "0 : 3360 / 3834 0.7043849229812622\n",
      "0 : 3520 / 3834 0.5553061962127686\n",
      "0 : 3680 / 3834 0.5256373882293701\n",
      "1 : 0 / 3834 0.6793232560157776\n",
      "1 : 160 / 3834 0.5923578143119812\n",
      "1 : 320 / 3834 0.4622243344783783\n",
      "1 : 480 / 3834 0.5648067593574524\n",
      "1 : 640 / 3834 0.643519937992096\n",
      "1 : 800 / 3834 0.6442902088165283\n",
      "1 : 960 / 3834 0.6773876547813416\n",
      "1 : 1120 / 3834 0.7272858619689941\n",
      "1 : 1280 / 3834 0.5859110355377197\n",
      "1 : 1440 / 3834 0.6259177923202515\n",
      "1 : 1600 / 3834 0.5418193936347961\n",
      "1 : 1760 / 3834 0.6212649941444397\n",
      "1 : 1920 / 3834 0.6705068945884705\n",
      "1 : 2080 / 3834 0.6801435351371765\n",
      "1 : 2240 / 3834 0.6444949507713318\n",
      "1 : 2400 / 3834 0.6638613343238831\n",
      "1 : 2560 / 3834 0.6624505519866943\n",
      "1 : 2720 / 3834 0.6629183888435364\n",
      "1 : 2880 / 3834 0.5299661755561829\n",
      "1 : 3040 / 3834 0.6434968709945679\n",
      "1 : 3200 / 3834 0.7251990437507629\n",
      "1 : 3360 / 3834 0.7105010151863098\n",
      "1 : 3520 / 3834 0.5502873659133911\n",
      "1 : 3680 / 3834 0.5298537015914917\n",
      "2 : 0 / 3834 0.6756109595298767\n",
      "2 : 160 / 3834 0.6179428100585938\n",
      "2 : 320 / 3834 0.4750766456127167\n",
      "2 : 480 / 3834 0.5628015995025635\n",
      "2 : 640 / 3834 0.6440570950508118\n",
      "2 : 800 / 3834 0.650334894657135\n",
      "2 : 960 / 3834 0.6756294965744019\n",
      "2 : 1120 / 3834 0.7441545724868774\n",
      "2 : 1280 / 3834 0.5775931477546692\n",
      "2 : 1440 / 3834 0.6211912631988525\n",
      "2 : 1600 / 3834 0.5358057022094727\n",
      "2 : 1760 / 3834 0.6213034391403198\n",
      "2 : 1920 / 3834 0.6656023859977722\n",
      "2 : 2080 / 3834 0.6659839153289795\n",
      "2 : 2240 / 3834 0.6435471177101135\n",
      "2 : 2400 / 3834 0.6633468866348267\n",
      "2 : 2560 / 3834 0.651604175567627\n",
      "2 : 2720 / 3834 0.6674027442932129\n",
      "2 : 2880 / 3834 0.5332341194152832\n",
      "2 : 3040 / 3834 0.6464200019836426\n",
      "2 : 3200 / 3834 0.7202153205871582\n",
      "2 : 3360 / 3834 0.7015448212623596\n",
      "2 : 3520 / 3834 0.5452182292938232\n",
      "2 : 3680 / 3834 0.5284646153450012\n",
      "3 : 0 / 3834 0.6755496263504028\n",
      "3 : 160 / 3834 0.6232755184173584\n",
      "3 : 320 / 3834 0.47438398003578186\n",
      "3 : 480 / 3834 0.5630877614021301\n",
      "3 : 640 / 3834 0.6440448760986328\n",
      "3 : 800 / 3834 0.6509039998054504\n",
      "3 : 960 / 3834 0.6758171916007996\n",
      "3 : 1120 / 3834 0.7450716495513916\n",
      "3 : 1280 / 3834 0.5783341526985168\n",
      "3 : 1440 / 3834 0.6211506724357605\n",
      "3 : 1600 / 3834 0.5355219841003418\n",
      "3 : 1760 / 3834 0.6213799118995667\n",
      "3 : 1920 / 3834 0.665327250957489\n",
      "3 : 2080 / 3834 0.6649077534675598\n",
      "3 : 2240 / 3834 0.6435431241989136\n",
      "3 : 2400 / 3834 0.6631677746772766\n",
      "3 : 2560 / 3834 0.6510142087936401\n",
      "3 : 2720 / 3834 0.6680971384048462\n",
      "3 : 2880 / 3834 0.5329762697219849\n",
      "3 : 3040 / 3834 0.6465132832527161\n",
      "3 : 3200 / 3834 0.7198660969734192\n",
      "3 : 3360 / 3834 0.7018764615058899\n",
      "3 : 3520 / 3834 0.5447661876678467\n",
      "3 : 3680 / 3834 0.5285352468490601\n",
      "4 : 0 / 3834 0.6754900813102722\n",
      "4 : 160 / 3834 0.6212430000305176\n",
      "4 : 320 / 3834 0.47347787022590637\n",
      "4 : 480 / 3834 0.5629540681838989\n",
      "4 : 640 / 3834 0.6439679861068726\n",
      "4 : 800 / 3834 0.6503182053565979\n",
      "4 : 960 / 3834 0.6750347018241882\n",
      "4 : 1120 / 3834 0.7441762685775757\n",
      "4 : 1280 / 3834 0.5753231048583984\n",
      "4 : 1440 / 3834 0.6210879683494568\n",
      "4 : 1600 / 3834 0.5358099341392517\n",
      "4 : 1760 / 3834 0.6216405630111694\n",
      "4 : 1920 / 3834 0.665290892124176\n",
      "4 : 2080 / 3834 0.6641767621040344\n",
      "4 : 2240 / 3834 0.6434916257858276\n",
      "4 : 2400 / 3834 0.6636536121368408\n",
      "4 : 2560 / 3834 0.6489214897155762\n",
      "4 : 2720 / 3834 0.6697981357574463\n",
      "4 : 2880 / 3834 0.5353372693061829\n",
      "4 : 3040 / 3834 0.648572564125061\n",
      "4 : 3200 / 3834 0.7207702398300171\n",
      "4 : 3360 / 3834 0.6983383893966675\n",
      "4 : 3520 / 3834 0.5449705719947815\n",
      "4 : 3680 / 3834 0.5275899767875671\n",
      "5 : 0 / 3834 0.6760265827178955\n",
      "5 : 160 / 3834 0.6327071189880371\n",
      "5 : 320 / 3834 0.48071572184562683\n",
      "5 : 480 / 3834 0.5643730163574219\n",
      "5 : 640 / 3834 0.6458559632301331\n",
      "5 : 800 / 3834 0.6537767052650452\n",
      "5 : 960 / 3834 0.6700268983840942\n",
      "5 : 1120 / 3834 0.7515959143638611\n",
      "5 : 1280 / 3834 0.5653470158576965\n",
      "5 : 1440 / 3834 0.6215484738349915\n",
      "5 : 1600 / 3834 0.5377389192581177\n",
      "5 : 1760 / 3834 0.6228095889091492\n",
      "5 : 1920 / 3834 0.6658294200897217\n",
      "5 : 2080 / 3834 0.6673102974891663\n",
      "5 : 2240 / 3834 0.6436424851417542\n",
      "5 : 2400 / 3834 0.6648817658424377\n",
      "5 : 2560 / 3834 0.6460610628128052\n",
      "5 : 2720 / 3834 0.6721965670585632\n",
      "5 : 2880 / 3834 0.5391702651977539\n",
      "5 : 3040 / 3834 0.6517879366874695\n",
      "5 : 3200 / 3834 0.7239406108856201\n",
      "5 : 3360 / 3834 0.6944503784179688\n",
      "5 : 3520 / 3834 0.5464286804199219\n",
      "5 : 3680 / 3834 0.5268073081970215\n",
      "6 : 0 / 3834 0.6764453649520874\n",
      "6 : 160 / 3834 0.6373734474182129\n",
      "6 : 320 / 3834 0.4836098849773407\n",
      "6 : 480 / 3834 0.5648919939994812\n",
      "6 : 640 / 3834 0.6467927694320679\n",
      "6 : 800 / 3834 0.6545718312263489\n",
      "6 : 960 / 3834 0.6692635416984558\n",
      "6 : 1120 / 3834 0.7492371797561646\n",
      "6 : 1280 / 3834 0.562852144241333\n",
      "6 : 1440 / 3834 0.6215060949325562\n",
      "6 : 1600 / 3834 0.5389190912246704\n",
      "6 : 1760 / 3834 0.6228684186935425\n",
      "6 : 1920 / 3834 0.6665452718734741\n",
      "6 : 2080 / 3834 0.6656328439712524\n",
      "6 : 2240 / 3834 0.6440237760543823\n",
      "6 : 2400 / 3834 0.6640164256095886\n",
      "6 : 2560 / 3834 0.6445379257202148\n",
      "6 : 2720 / 3834 0.6729254126548767\n",
      "6 : 2880 / 3834 0.5440529584884644\n",
      "6 : 3040 / 3834 0.6537134647369385\n",
      "6 : 3200 / 3834 0.7292262315750122\n",
      "6 : 3360 / 3834 0.6924228072166443\n",
      "6 : 3520 / 3834 0.5497841835021973\n",
      "6 : 3680 / 3834 0.5263820886611938\n",
      "7 : 0 / 3834 0.6779881715774536\n",
      "7 : 160 / 3834 0.6445485949516296\n",
      "7 : 320 / 3834 0.48931509256362915\n",
      "7 : 480 / 3834 0.5654802322387695\n",
      "7 : 640 / 3834 0.6492255330085754\n",
      "7 : 800 / 3834 0.6549460291862488\n",
      "7 : 960 / 3834 0.6655359864234924\n",
      "7 : 1120 / 3834 0.7527695298194885\n",
      "7 : 1280 / 3834 0.5543409585952759\n",
      "7 : 1440 / 3834 0.6222184896469116\n",
      "7 : 1600 / 3834 0.5421098470687866\n",
      "7 : 1760 / 3834 0.6238032579421997\n",
      "7 : 1920 / 3834 0.6679859161376953\n",
      "7 : 2080 / 3834 0.6670498847961426\n",
      "7 : 2240 / 3834 0.6447672247886658\n",
      "7 : 2400 / 3834 0.6648973226547241\n",
      "7 : 2560 / 3834 0.6439564228057861\n",
      "7 : 2720 / 3834 0.6727631092071533\n",
      "7 : 2880 / 3834 0.5462400913238525\n",
      "7 : 3040 / 3834 0.6540842056274414\n",
      "7 : 3200 / 3834 0.7319154143333435\n",
      "7 : 3360 / 3834 0.6919776201248169\n",
      "7 : 3520 / 3834 0.5518653988838196\n",
      "7 : 3680 / 3834 0.5263181328773499\n",
      "8 : 0 / 3834 0.6795797944068909\n",
      "8 : 160 / 3834 0.6462161540985107\n",
      "8 : 320 / 3834 0.49756136536598206\n",
      "8 : 480 / 3834 0.5658711791038513\n",
      "8 : 640 / 3834 0.6519187688827515\n",
      "8 : 800 / 3834 0.655026376247406\n",
      "8 : 960 / 3834 0.6639267206192017\n",
      "8 : 1120 / 3834 0.7520028948783875\n",
      "8 : 1280 / 3834 0.5502790808677673\n",
      "8 : 1440 / 3834 0.622320294380188\n",
      "8 : 1600 / 3834 0.5443207621574402\n",
      "8 : 1760 / 3834 0.6239360570907593\n",
      "8 : 1920 / 3834 0.6691347360610962\n",
      "8 : 2080 / 3834 0.6654828786849976\n",
      "8 : 2240 / 3834 0.6457386612892151\n",
      "8 : 2400 / 3834 0.663271427154541\n",
      "8 : 2560 / 3834 0.6434935927391052\n",
      "8 : 2720 / 3834 0.6731086373329163\n",
      "8 : 2880 / 3834 0.5552943348884583\n",
      "8 : 3040 / 3834 0.6553381085395813\n",
      "8 : 3200 / 3834 0.7412383556365967\n",
      "8 : 3360 / 3834 0.6911067962646484\n",
      "8 : 3520 / 3834 0.5584501028060913\n",
      "8 : 3680 / 3834 0.5263456702232361\n",
      "9 : 0 / 3834 0.6829806566238403\n",
      "9 : 160 / 3834 0.6475323438644409\n",
      "9 : 320 / 3834 0.5073457360267639\n",
      "9 : 480 / 3834 0.5660236477851868\n",
      "9 : 640 / 3834 0.6555099487304688\n",
      "9 : 800 / 3834 0.6542534828186035\n",
      "9 : 960 / 3834 0.6625134348869324\n",
      "9 : 1120 / 3834 0.7495554089546204\n",
      "9 : 1280 / 3834 0.5458802580833435\n",
      "9 : 1440 / 3834 0.622205913066864\n",
      "9 : 1600 / 3834 0.5472316145896912\n",
      "9 : 1760 / 3834 0.623805046081543\n",
      "9 : 1920 / 3834 0.6706607341766357\n",
      "9 : 2080 / 3834 0.6623468399047852\n",
      "9 : 2240 / 3834 0.6468349695205688\n",
      "9 : 2400 / 3834 0.662948727607727\n",
      "9 : 2560 / 3834 0.6435564756393433\n",
      "9 : 2720 / 3834 0.6730399131774902\n",
      "9 : 2880 / 3834 0.5574108958244324\n",
      "9 : 3040 / 3834 0.6552879810333252\n",
      "9 : 3200 / 3834 0.7433381080627441\n",
      "9 : 3360 / 3834 0.6912904381752014\n",
      "9 : 3520 / 3834 0.56109219789505\n",
      "9 : 3680 / 3834 0.5267223715782166\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array([(0 if c['label'] == 'n' else 1) for c in train_comments])\n",
    "test_y = np.array([(0 if c['label'] == 'n' else 1) for c in test_comments])\n",
    "\n",
    "idx = np.arange(len(train_comments), dtype='int32')\n",
    "\n",
    "classModel = BiLSTMClassifier(blm).to(device)\n",
    "optimizer = torch.optim.Adam(classModel.parameters(), lr=0.01)\n",
    "\n",
    "idx = np.arange(len(train_comments), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "for e in range(10):\n",
    "    for b in range(0, len(idx), batchSize):\n",
    "        batch = [ train_comments[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "        target = torch.tensor(train_y[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "\n",
    "        Z = classModel(batch)\n",
    "        H = torch.nn.functional.cross_entropy(Z,target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        H.backward()\n",
    "        optimizer.step()\n",
    "        if b % 10 == 0:\n",
    "            print(e, ':', b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(s, class_model):\n",
    "    with torch.no_grad():\n",
    "        Z = class_model([s])\n",
    "        return torch.argmax(Z[0]).item()\n",
    "\n",
    "def test_model(model):\n",
    "    tp, fn, fp, tn = 0, 0, 0, 0\n",
    "    for comment in test_comments:\n",
    "        if predict(comment['comment'], model):\n",
    "            if comment['label'] == 'p':\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if comment['label'] == 'p':\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    precision = tp/(tp + fp) if (tp + fp) != 0 else 0\n",
    "    recall = tp/(tp + fn)\n",
    "    Fscore = (2.0 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    print('Precision: '+str(precision))\n",
    "    print('Recall: '+str(recall))\n",
    "    print('F1-score: '+str(Fscore))\n",
    "    print('Confusion Matrix:')\n",
    "    print('{:15} {:>8} {:>8}'.format('', 'Predicted p', 'Predicted n'))\n",
    "    print('{:15} {:>8} {:>8}'.format('Actual p', tp, fn))\n",
    "    print('{:15} {:>8} {:>8}'.format('Actual n', fp, tn))\n",
    "    return Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1111111111111111\n",
      "Recall: 0.015384615384615385\n",
      "F1-score: 0.02702702702702703\n",
      "Confusion Matrix:\n",
      "                Predicted p Predicted n\n",
      "Actual p               1       64\n",
      "Actual n               8      128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02702702702702703"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(classModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in supervised_comments:\n",
    "    if predict(c['comment'], classModel) == 1:\n",
    "        print(c['label'], c['comment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
