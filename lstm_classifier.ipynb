{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tokenizers import Tokenizer\n",
    "from preprocessing import cyrillize\n",
    "\n",
    "import json\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(f) -> list[str]:\n",
    "    all = []\n",
    "    for a in json.load(f):\n",
    "        sentences = a['content'].lower().split('.')\n",
    "        all.append(a['name'].lower())\n",
    "        all += sentences\n",
    "\n",
    "    return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/unsupervised_comments.json', 'r', encoding=\"utf-8\") as f:\n",
    "    unsupervised_comments = json.load(f)\n",
    "\n",
    "with open('data/blitz_articles.json', 'r', encoding=\"utf-8\") as f:\n",
    "    sentences = get_sentences(f)\n",
    "\n",
    "with open('data/dnes_bg_articles.json', 'r', encoding=\"utf-8\") as f:\n",
    "    sentences += get_sentences(f)\n",
    "\n",
    "with open('data/pik_articles.json', 'r', encoding=\"utf-8\") as f:\n",
    "    sentences += get_sentences(f)\n",
    "\n",
    "\n",
    "unsupervised_corpus = unsupervised_comments + sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the supervised corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/blitz_comments.json', 'r', encoding=\"utf-8\") as f:\n",
    "    supervised_comments = [{'comment': cyrillize(d['comment']), 'label': d['label']} for d in json.load(f) if 'label' in d]\n",
    "\n",
    "supervised_p = len([s for s in supervised_comments if s['label'] == 'p'])\n",
    "supervised_n = len([s for s in supervised_comments if s['label'] == 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bgjargon.json', 'r', encoding=\"utf-8\") as f:\n",
    "    bgjargon = json.load(f)\n",
    "\n",
    "with open('data/bad_words_2.json', 'r', encoding=\"utf-8\") as f:\n",
    "    bad_words = set(json.load(f))\n",
    "\n",
    "for w in bad_words:\n",
    "    if w in bgjargon:\n",
    "        for meaning in bgjargon[w]['meanings']:\n",
    "            if len(meaning['example']) > 0 and supervised_p < supervised_n:\n",
    "                supervised_p += 1\n",
    "                supervised_comments.append({'comment': meaning['example'], 'label': 'p'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"data/tokenizer_comments_bgjargon_articles_end_start.json\")\n",
    "token2ind = tokenizer.get_vocab()\n",
    "ind2token = tokenizer.id_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_corpus = [tokenizer.encode(c.lower()).tokens for c in unsupervised_corpus]\n",
    "supervised_comments = [{'comment': tokenizer.encode(c['comment'].lower()).tokens, 'label': c['label']} for c in supervised_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_comments(supervised_comments, test_fraction = 0.1):\n",
    "    random.seed(42)\n",
    "    random.shuffle(supervised_comments)\n",
    "    test_count = int(len(supervised_comments) * test_fraction)\n",
    "    test_comments = supervised_comments[:test_count]\n",
    "    train_comments = supervised_comments[test_count:]\n",
    "    return test_comments, train_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre training BiLSTM on the unsuppervised corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '[STR]'\n",
    "end_token = '[END]'\n",
    "unk_token = '[UNK]'\n",
    "pad_token = '[PAD]'\n",
    "\n",
    "batchSize = 32\n",
    "emb_size = 50\n",
    "hid_size = 100\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "test_comments, train_comments  = split_comments(supervised_comments, test_fraction = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, token2ind, unk_token, pad_token, end_token):\n",
    "        super(BiLSTMLanguageModelPack, self).__init__()\n",
    "        self.token2ind = token2ind\n",
    "        self.unk_token_idx = token2ind[unk_token]\n",
    "        self.pad_token_idx = token2ind[pad_token]\n",
    "        self.end_token_idx = token2ind[end_token]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "        self.embed = torch.nn.Embedding(len(token2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(2*hidden_size,len(token2ind))\n",
    "\n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        comments = [[self.token2ind.get(w,self.unk_token_idx) for w in s] for s in source]\n",
    "        comments_padded = [ s+(m-len(s))*[self.pad_token_idx] for s in comments]\n",
    "        return torch.t(torch.tensor(comments_padded, dtype=torch.long, device=device))\n",
    "\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.embed(X)\n",
    "\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        m = X.shape[0]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths, enforce_sorted=False))\n",
    "\n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        output = output.view(m, batch_size, 2, self.hidden_size)\n",
    "        # left to right and right to left in shift the prediction to i + 1 and i - 1 for the right to left\n",
    "        # we shift them to make them predict a single position\n",
    "        t = torch.cat((output[:-2,:,0,:], output[2:,:,1,:]),2)\n",
    "        Z = self.projection(t.flatten(0,1))\n",
    "\n",
    "        Y_bar = X[1:-1].flatten(0,1)\n",
    "        Y_bar[Y_bar==self.end_token_idx] = self.pad_token_idx\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.pad_token_idx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0 / 3454 10.315394401550293\n",
      "0 : 800 / 3454 7.925639629364014\n",
      "0 : 1600 / 3454 7.846607208251953\n",
      "0 : 2400 / 3454 7.593648433685303\n",
      "0 : 3200 / 3454 7.320993900299072\n",
      "1 : 0 / 3454 6.6537322998046875\n",
      "1 : 800 / 3454 6.3167009353637695\n",
      "1 : 1600 / 3454 6.385562896728516\n",
      "1 : 2400 / 3454 6.08720064163208\n",
      "1 : 3200 / 3454 5.793009281158447\n",
      "2 : 0 / 3454 5.1672682762146\n",
      "2 : 800 / 3454 4.7709832191467285\n",
      "2 : 1600 / 3454 4.687723636627197\n",
      "2 : 2400 / 3454 4.256646633148193\n",
      "2 : 3200 / 3454 4.119178295135498\n",
      "3 : 0 / 3454 3.334012031555176\n",
      "3 : 800 / 3454 3.4363796710968018\n",
      "3 : 1600 / 3454 3.4834465980529785\n",
      "3 : 2400 / 3454 3.114901542663574\n",
      "3 : 3200 / 3454 3.0795207023620605\n",
      "4 : 0 / 3454 2.29461407661438\n",
      "4 : 800 / 3454 2.4076406955718994\n",
      "4 : 1600 / 3454 2.697399377822876\n",
      "4 : 2400 / 3454 2.3358359336853027\n",
      "4 : 3200 / 3454 2.3799140453338623\n"
     ]
    }
   ],
   "source": [
    "blm = BiLSTMLanguageModelPack(emb_size, hid_size, token2ind, unk_token, pad_token, end_token).to(device)\n",
    "optimizer = torch.optim.Adam(blm.parameters(), lr=0.01)\n",
    "\n",
    "idx = np.arange(len(train_comments), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "for e in range(5):\n",
    "    for b in range(0, len(idx), batchSize):\n",
    "        batch = [unsupervised_corpus[i] for i in idx[b:min(b+batchSize, len(idx))]]\n",
    "        H = blm(batch)\n",
    "        optimizer.zero_grad()\n",
    "        H.backward()\n",
    "        optimizer.step()\n",
    "        if b % 100 == 0:\n",
    "            print(e, ':', b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, test_comments, batchSize):\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(0,len(test_comments),batchSize):\n",
    "        batch = test_comments[b:min(b+batchSize, len(test_comments))]\n",
    "        l = sum(len(s)-1 for s in batch)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * lm(batch)\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3062.1473010399154"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(blm, [c['comment'] for c in supervised_comments], batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning on the supervised comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, langModel):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.langModel = langModel\n",
    "        self.classProjection = torch.nn.Linear(2*langModel.hidden_size, 2)\n",
    "\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.langModel.preparePaddedBatch(source)\n",
    "        E = self.langModel.embed(X)\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        _, (h,c) = self.langModel.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths, enforce_sorted=False))\n",
    "        h = h.view(2,batch_size,self.langModel.hidden_size)\n",
    "\n",
    "        Z = self.classProjection(torch.cat([h[0],h[1]],1))\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0 / 3454 0.6660460829734802\n",
      "0 : 160 / 3454 0.6398159861564636\n",
      "0 : 320 / 3454 0.6253937482833862\n",
      "0 : 480 / 3454 0.6303751468658447\n",
      "0 : 640 / 3454 0.8149018287658691\n",
      "0 : 800 / 3454 0.6577979326248169\n",
      "0 : 960 / 3454 0.6757951378822327\n",
      "0 : 1120 / 3454 0.7374864816665649\n",
      "0 : 1280 / 3454 0.5801318883895874\n",
      "0 : 1440 / 3454 0.7486447095870972\n",
      "0 : 1600 / 3454 0.5848121643066406\n",
      "0 : 1760 / 3454 0.6211056113243103\n",
      "0 : 1920 / 3454 0.8195732831954956\n",
      "0 : 2080 / 3454 0.6773115992546082\n",
      "0 : 2240 / 3454 0.5846858620643616\n",
      "0 : 2400 / 3454 0.6723805665969849\n",
      "0 : 2560 / 3454 0.6226780414581299\n",
      "0 : 2720 / 3454 0.6829150915145874\n",
      "0 : 2880 / 3454 0.6158624887466431\n",
      "0 : 3040 / 3454 0.6295149922370911\n",
      "0 : 3200 / 3454 0.5630736947059631\n",
      "0 : 3360 / 3454 0.6908990740776062\n",
      "1 : 0 / 3454 0.6782326102256775\n",
      "1 : 160 / 3454 0.621475875377655\n",
      "1 : 320 / 3454 0.5641404986381531\n",
      "1 : 480 / 3454 0.6225164532661438\n",
      "1 : 640 / 3454 0.7401736974716187\n",
      "1 : 800 / 3454 0.5941594839096069\n",
      "1 : 960 / 3454 0.6754659414291382\n",
      "1 : 1120 / 3454 0.6854835748672485\n",
      "1 : 1280 / 3454 0.582922101020813\n",
      "1 : 1440 / 3454 0.7953944206237793\n",
      "1 : 1600 / 3454 0.4812152087688446\n",
      "1 : 1760 / 3454 0.6283501982688904\n",
      "1 : 1920 / 3454 0.7329530119895935\n",
      "1 : 2080 / 3454 0.6917157769203186\n",
      "1 : 2240 / 3454 0.5641968846321106\n",
      "1 : 2400 / 3454 0.6618068814277649\n",
      "1 : 2560 / 3454 0.6211686730384827\n",
      "1 : 2720 / 3454 0.6850014328956604\n",
      "1 : 2880 / 3454 0.6104228496551514\n",
      "1 : 3040 / 3454 0.6304721236228943\n",
      "1 : 3200 / 3454 0.567237913608551\n",
      "1 : 3360 / 3454 0.6903545260429382\n",
      "2 : 0 / 3454 0.6865341663360596\n",
      "2 : 160 / 3454 0.6231846809387207\n",
      "2 : 320 / 3454 0.5609216094017029\n",
      "2 : 480 / 3454 0.6242935657501221\n",
      "2 : 640 / 3454 0.7230908274650574\n",
      "2 : 800 / 3454 0.5943750739097595\n",
      "2 : 960 / 3454 0.6776708960533142\n",
      "2 : 1120 / 3454 0.6856010556221008\n",
      "2 : 1280 / 3454 0.5959553122520447\n",
      "2 : 1440 / 3454 0.776932954788208\n",
      "2 : 1600 / 3454 0.46135008335113525\n",
      "2 : 1760 / 3454 0.6241883039474487\n",
      "2 : 1920 / 3454 0.7248449325561523\n",
      "2 : 2080 / 3454 0.6824558973312378\n",
      "2 : 2240 / 3454 0.564594566822052\n",
      "2 : 2400 / 3454 0.6635811924934387\n",
      "2 : 2560 / 3454 0.6220829486846924\n",
      "2 : 2720 / 3454 0.687807559967041\n",
      "2 : 2880 / 3454 0.6110206842422485\n",
      "2 : 3040 / 3454 0.6326619386672974\n",
      "2 : 3200 / 3454 0.5720870494842529\n",
      "2 : 3360 / 3454 0.6868003010749817\n",
      "3 : 0 / 3454 0.6889734268188477\n",
      "3 : 160 / 3454 0.6254923939704895\n",
      "3 : 320 / 3454 0.5531368255615234\n",
      "3 : 480 / 3454 0.6244950890541077\n",
      "3 : 640 / 3454 0.707836925983429\n",
      "3 : 800 / 3454 0.5941307544708252\n",
      "3 : 960 / 3454 0.6823365688323975\n",
      "3 : 1120 / 3454 0.6877537369728088\n",
      "3 : 1280 / 3454 0.6033493280410767\n",
      "3 : 1440 / 3454 0.7505500912666321\n",
      "3 : 1600 / 3454 0.46107059717178345\n",
      "3 : 1760 / 3454 0.6219441890716553\n",
      "3 : 1920 / 3454 0.7300300598144531\n",
      "3 : 2080 / 3454 0.6809278726577759\n",
      "3 : 2240 / 3454 0.5656221508979797\n",
      "3 : 2400 / 3454 0.6610658764839172\n",
      "3 : 2560 / 3454 0.6224837303161621\n",
      "3 : 2720 / 3454 0.6907263994216919\n",
      "3 : 2880 / 3454 0.6090901494026184\n",
      "3 : 3040 / 3454 0.6330965161323547\n",
      "3 : 3200 / 3454 0.5753797292709351\n",
      "3 : 3360 / 3454 0.6832104325294495\n",
      "4 : 0 / 3454 0.687950849533081\n",
      "4 : 160 / 3454 0.6266347169876099\n",
      "4 : 320 / 3454 0.54808509349823\n",
      "4 : 480 / 3454 0.6236985921859741\n",
      "4 : 640 / 3454 0.7039254903793335\n",
      "4 : 800 / 3454 0.5942112803459167\n",
      "4 : 960 / 3454 0.6832141280174255\n",
      "4 : 1120 / 3454 0.6887910962104797\n",
      "4 : 1280 / 3454 0.6030555367469788\n",
      "4 : 1440 / 3454 0.7468760013580322\n",
      "4 : 1600 / 3454 0.46305137872695923\n",
      "4 : 1760 / 3454 0.6218439340591431\n",
      "4 : 1920 / 3454 0.7313861846923828\n",
      "4 : 2080 / 3454 0.6813324689865112\n",
      "4 : 2240 / 3454 0.5656999349594116\n",
      "4 : 2400 / 3454 0.6607680916786194\n",
      "4 : 2560 / 3454 0.6224011778831482\n",
      "4 : 2720 / 3454 0.6906100511550903\n",
      "4 : 2880 / 3454 0.6090409755706787\n",
      "4 : 3040 / 3454 0.6329939365386963\n",
      "4 : 3200 / 3454 0.5753567814826965\n",
      "4 : 3360 / 3454 0.6830120086669922\n",
      "5 : 0 / 3454 0.6876295804977417\n",
      "5 : 160 / 3454 0.626450777053833\n",
      "5 : 320 / 3454 0.5489429235458374\n",
      "5 : 480 / 3454 0.6233900189399719\n",
      "5 : 640 / 3454 0.7028060555458069\n",
      "5 : 800 / 3454 0.5942556262016296\n",
      "5 : 960 / 3454 0.6845844388008118\n",
      "5 : 1120 / 3454 0.6899383664131165\n",
      "5 : 1280 / 3454 0.6036829948425293\n",
      "5 : 1440 / 3454 0.7407861948013306\n",
      "5 : 1600 / 3454 0.4653211832046509\n",
      "5 : 1760 / 3454 0.6216088533401489\n",
      "5 : 1920 / 3454 0.731950581073761\n",
      "5 : 2080 / 3454 0.6811635494232178\n",
      "5 : 2240 / 3454 0.5657280087471008\n",
      "5 : 2400 / 3454 0.6598513722419739\n",
      "5 : 2560 / 3454 0.6226017475128174\n",
      "5 : 2720 / 3454 0.6922371983528137\n",
      "5 : 2880 / 3454 0.6077149510383606\n",
      "5 : 3040 / 3454 0.6328219771385193\n",
      "5 : 3200 / 3454 0.5775325298309326\n",
      "5 : 3360 / 3454 0.6804537773132324\n",
      "6 : 0 / 3454 0.6863032579421997\n",
      "6 : 160 / 3454 0.6270620226860046\n",
      "6 : 320 / 3454 0.544625461101532\n",
      "6 : 480 / 3454 0.6228674054145813\n",
      "6 : 640 / 3454 0.701291024684906\n",
      "6 : 800 / 3454 0.594454288482666\n",
      "6 : 960 / 3454 0.683883547782898\n",
      "6 : 1120 / 3454 0.6900550723075867\n",
      "6 : 1280 / 3454 0.6024472713470459\n",
      "6 : 1440 / 3454 0.7420125603675842\n",
      "6 : 1600 / 3454 0.46539273858070374\n",
      "6 : 1760 / 3454 0.621684193611145\n",
      "6 : 1920 / 3454 0.7315595746040344\n",
      "6 : 2080 / 3454 0.6811841130256653\n",
      "6 : 2240 / 3454 0.5656712651252747\n",
      "6 : 2400 / 3454 0.6600370407104492\n",
      "6 : 2560 / 3454 0.6225939393043518\n",
      "6 : 2720 / 3454 0.69205641746521\n",
      "6 : 2880 / 3454 0.6078848838806152\n",
      "6 : 3040 / 3454 0.6328681111335754\n",
      "6 : 3200 / 3454 0.577300488948822\n",
      "6 : 3360 / 3454 0.6807493567466736\n",
      "7 : 0 / 3454 0.6865028142929077\n",
      "7 : 160 / 3454 0.6270328164100647\n",
      "7 : 320 / 3454 0.5449097752571106\n",
      "7 : 480 / 3454 0.6229406595230103\n",
      "7 : 640 / 3454 0.7014526724815369\n",
      "7 : 800 / 3454 0.5944275259971619\n",
      "7 : 960 / 3454 0.6838541030883789\n",
      "7 : 1120 / 3454 0.6899562478065491\n",
      "7 : 1280 / 3454 0.602509081363678\n",
      "7 : 1440 / 3454 0.7423919439315796\n",
      "7 : 1600 / 3454 0.4651654362678528\n",
      "7 : 1760 / 3454 0.6216925382614136\n",
      "7 : 1920 / 3454 0.7315608859062195\n",
      "7 : 2080 / 3454 0.6811937689781189\n",
      "7 : 2240 / 3454 0.5656756162643433\n",
      "7 : 2400 / 3454 0.6600876450538635\n",
      "7 : 2560 / 3454 0.6225805282592773\n",
      "7 : 2720 / 3454 0.6919527053833008\n",
      "7 : 2880 / 3454 0.6079749464988708\n",
      "7 : 3040 / 3454 0.6328887939453125\n",
      "7 : 3200 / 3454 0.5771368145942688\n",
      "7 : 3360 / 3454 0.680950939655304\n",
      "8 : 0 / 3454 0.6866309642791748\n",
      "8 : 160 / 3454 0.6270071864128113\n",
      "8 : 320 / 3454 0.5451218485832214\n",
      "8 : 480 / 3454 0.622994065284729\n",
      "8 : 640 / 3454 0.7015849351882935\n",
      "8 : 800 / 3454 0.594408392906189\n",
      "8 : 960 / 3454 0.6838239431381226\n",
      "8 : 1120 / 3454 0.6898773312568665\n",
      "8 : 1280 / 3454 0.6025417447090149\n",
      "8 : 1440 / 3454 0.7426954507827759\n",
      "8 : 1600 / 3454 0.46500363945961\n",
      "8 : 1760 / 3454 0.6217010021209717\n",
      "8 : 1920 / 3454 0.731555700302124\n",
      "8 : 2080 / 3454 0.6812036037445068\n",
      "8 : 2240 / 3454 0.5656775236129761\n",
      "8 : 2400 / 3454 0.6601294279098511\n",
      "8 : 2560 / 3454 0.6225705146789551\n",
      "8 : 2720 / 3454 0.6918718218803406\n",
      "8 : 2880 / 3454 0.6080435514450073\n",
      "8 : 3040 / 3454 0.6329026818275452\n",
      "8 : 3200 / 3454 0.5770159959793091\n",
      "8 : 3360 / 3454 0.6810976266860962\n",
      "9 : 0 / 3454 0.6867220401763916\n",
      "9 : 160 / 3454 0.6269866824150085\n",
      "9 : 320 / 3454 0.5452810525894165\n",
      "9 : 480 / 3454 0.6230334639549255\n",
      "9 : 640 / 3454 0.701675295829773\n",
      "9 : 800 / 3454 0.594395101070404\n",
      "9 : 960 / 3454 0.6838071942329407\n",
      "9 : 1120 / 3454 0.6898276209831238\n",
      "9 : 1280 / 3454 0.6025912165641785\n",
      "9 : 1440 / 3454 0.7428365349769592\n",
      "9 : 1600 / 3454 0.4649399220943451\n",
      "9 : 1760 / 3454 0.6217057108879089\n",
      "9 : 1920 / 3454 0.73158860206604\n",
      "9 : 2080 / 3454 0.681222140789032\n",
      "9 : 2240 / 3454 0.5656812787055969\n",
      "9 : 2400 / 3454 0.6601496338844299\n",
      "9 : 2560 / 3454 0.6225601434707642\n",
      "9 : 2720 / 3454 0.6918097734451294\n",
      "9 : 2880 / 3454 0.6080873012542725\n",
      "9 : 3040 / 3454 0.6329068541526794\n",
      "9 : 3200 / 3454 0.5769448280334473\n",
      "9 : 3360 / 3454 0.6811847686767578\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array([(0 if c['label'] == 'n' else 1) for c in train_comments])\n",
    "test_y = np.array([(0 if c['label'] == 'n' else 1) for c in test_comments])\n",
    "\n",
    "idx = np.arange(len(train_comments), dtype='int32')\n",
    "\n",
    "classModel = BiLSTMClassifier(blm).to(device)\n",
    "optimizer = torch.optim.Adam(classModel.parameters(), lr=0.01)\n",
    "\n",
    "idx = np.arange(len(train_comments), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "for e in range(10):\n",
    "    for b in range(0, len(idx), batchSize):\n",
    "        batch = [ train_comments[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "        target = torch.tensor(train_y[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "\n",
    "        Z = classModel(batch)\n",
    "        H = torch.nn.functional.cross_entropy(Z,target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        H.backward()\n",
    "        optimizer.step()\n",
    "        if b % 10 == 0:\n",
    "            print(e, ':', b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(s, class_model):\n",
    "    with torch.no_grad():\n",
    "        Z = class_model([s])\n",
    "        return torch.argmax(Z[0]).item()\n",
    "\n",
    "def test_model(model):\n",
    "    tp, fn, fp, tn = 0, 0, 0, 0\n",
    "    for comment in test_comments:\n",
    "        if predict(comment['comment'], model):\n",
    "            if comment['label'] == 'p':\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if comment['label'] == 'p':\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    precision = tp/(tp + fp) if (tp + fp) != 0 else 0\n",
    "    recall = tp/(tp + fn)\n",
    "    Fscore = (2.0 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    print('Precision: '+str(precision))\n",
    "    print('Recall: '+str(recall))\n",
    "    print('F1-score: '+str(Fscore))\n",
    "    print('Confusion Matrix:')\n",
    "    print('{:15} {:>8} {:>8}'.format('', 'Predicted p', 'Predicted n'))\n",
    "    print('{:15} {:>8} {:>8}'.format('Actual p', tp, fn))\n",
    "    print('{:15} {:>8} {:>8}'.format('Actual n', fp, tn))\n",
    "    return Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3684210526315789\n",
      "Recall: 0.45161290322580644\n",
      "F1-score: 0.40579710144927533\n",
      "Confusion Matrix:\n",
      "                Predicted p Predicted n\n",
      "Actual p              28       34\n",
      "Actual n              48       71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40579710144927533"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(classModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in supervised_comments:\n",
    "    if predict(c['comment'], classModel) == 1:\n",
    "        print(c['label'], c['comment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
